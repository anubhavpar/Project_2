{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code Section for Declaring Imports##\n",
    "\n",
    "from bs4 import BeautifulSoup # Load the libraries for beautiful soup\n",
    "import requests\n",
    "#import urllib2\n",
    "import time \n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "import pageviewapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "#Setting Options\n",
    "pd.set_option('display.max_columns', 75)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_float(value):\n",
    "    return f'{value:,.2f}'\n",
    "\n",
    "pd.options.display.float_format = format_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Code Section for Beautiful Soup Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code Section for Beautiful Soup Headers##\n",
    "\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "\n",
    "page = \"https://fbref.com/en/comps/9/1526/2016-2017-Premier-League-Stats\"\n",
    "pageTree = requests.get(page, headers=headers)\n",
    "pageSoup_teams = BeautifulSoup(pageTree.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Code Section to fetch the Teams - Source : Fbref.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code Section to fetch the Teams ##\n",
    "\n",
    "Player_Teams = []\n",
    "Player_Teams_upd_mod = []\n",
    "Player_Teams_upd = []\n",
    "table = pageSoup_teams.find('table', class_ = 'min_width sortable stats_table')\n",
    "for link in table.find_all('a'):\n",
    "        temp = \"https://fbref.com\" + link.get(\"href\") \n",
    "        #temp_17 = \"https://fbref.com\" + link.get(\"href\") \n",
    "        team_name = link.text\n",
    "        Player_Teams.append([team_name,temp])\n",
    "        #Player_Teams.append([team_name,temp_16])\n",
    "\n",
    "#Player_Teams_upd_2016 = []\n",
    "#Player_Teams_upd_2017 = []\n",
    "\n",
    "for value in Player_Teams:\n",
    "    if value[1][-1:-6:-1] == 'statS':\n",
    "        Player_Teams_upd.append(value)\n",
    "\n",
    "[Player_Teams_upd_mod.append(x) for x in Player_Teams_upd if x not in Player_Teams_upd_mod];        \n",
    "\n",
    "#for value in Player_Teams_2017:\n",
    "#    if value[1][-1:-6:-1] == 'statS':\n",
    "#        Player_Teams_upd_2017.append(value)\n",
    "\n",
    "        \n",
    "#Player_Teams_upd;        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Teams_upd_mod;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Code Section to fetch the Players from Teams - Source : Fbref.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code Section to fetch Player List from Teams ##\n",
    "\n",
    "Players_Info = {}\n",
    "for player_page in Player_Teams_upd:\n",
    "    page = player_page[1]\n",
    "    player_team = player_page[0]\n",
    "    pageTree = requests.get(page, headers=headers)\n",
    "    pageSoup_teams = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "    \n",
    "    for table in pageSoup_teams.find_all('div', id = 'div_stats_standard_1526'):\n",
    "        rows = [row for row in table.find_all('tr')]\n",
    "    for index in range(2,len(rows)-2):\n",
    "        player_name =     rows[index].find_all('th')[0].find('a').text\n",
    "        player_url  =     'https://fbref.com' + rows[index].find_all('th')[0].find('a')['href']\n",
    "        player_details =  rows[index].find_all('td')\n",
    "        Players_Info[player_name] = [player_name] + [player_url] + [player_team] + [i.text for i in player_details[:-1]] \n",
    "\n",
    "Players_Info_df = pd.DataFrame(Players_Info).T  #transpose\n",
    "Players_Info_df.columns = ['Player','PlLink','Team','Nation', 'Pos','Age','MP','Starts','Min','90s','Gls','Ast', \n",
    "                    'PK','PKatt','CrdY','CrdR','PGls','PAst','PG+A','PG-PK','PG+A-PK'] \n",
    "Players_Info_df.set_index('Player', inplace= True)\n",
    "Players_Info_df;        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Info_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Code Section to fetch Player level Attributes - Source : Fbref.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code Section to fetch Specific Player Attributes##\n",
    "Player_Attr = {}\n",
    "Player_Shooting = {}\n",
    "for index, row in enumerate(Players_Info_df.itertuples()):\n",
    "    page = row.PlLink\n",
    "    pageTree = requests.get(page, headers=headers)\n",
    "    pageSoup_player = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "    #pageSoup_player \n",
    "    for table in pageSoup_player.find_all('div', class_ = 'players', id = 'info'):\n",
    "        #print(table)\n",
    "        rows = [row for row in table.find_all('p')]\n",
    "        headings = [heading for heading in table.find_all('h1') ]\n",
    "    try:   \n",
    "        #print(headings[0])\n",
    "        player_name   = headings[0].find('span').text\n",
    "        #print(player_name)\n",
    "        player_height = rows[2].find_all('span')[0].text\n",
    "        player_weight = rows[2].find_all('span')[1].text\n",
    "        player_footedness = rows[1].text\n",
    "        Player_Attr[player_name] = [player_name] + [player_height] + [player_weight] + [player_footedness]\n",
    "    except:\n",
    "        player_name   = 'Error'\n",
    "        player_height = 'Error'\n",
    "        player_weight = 'Error'\n",
    "        player_footedness = 'Error'\n",
    "        Player_Attr[player_name] = [player_name] + [player_height] + [player_weight] + [player_footedness]\n",
    "        continue\n",
    "#    for table in pageSoup_player.find_all('div', id = 'div_stats_shooting_dom_lg'):\n",
    "#        rows = [row for row in table.find_all('tr')]\n",
    "        #for index in range(4:18): \n",
    "#        items = rows[12].find_all('td')\n",
    "#        Player_Shooting[player_name] = [player_name] + [i.text for i in items[4:]]\n",
    "\n",
    "#print(Player_Shooting)\n",
    "#Players_Shooting_df = pd.DataFrame(Player_Shooting).T \n",
    "#Players_Shooting_df.columns = ['Player','','Weight','Footedness']#print(rows[3])\n",
    "\n",
    "Players_Attr_df = pd.DataFrame(Player_Attr).T  #transpose\n",
    "Players_Attr_df.columns = ['Player','Height','Weight','Footedness'] \n",
    "Players_Attr_df.set_index('Player', inplace= True)\n",
    "## Merge the above different Player specific information into a single DataFrame for players\n",
    "Players_Info_outer_merged = Players_Info_df.merge(Players_Attr_df, how='inner', left_on='Player', right_on='Player')\n",
    "#Players_Info_outer_merged = pd.merge(Players_Info_df, Players_Attr_df,\n",
    "#                        how=\"outer\", on=[\"Player\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Info_outer_merged;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Code Section to fetch markvet value of the Players - Source : Transfermarkt.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Beautiful Soup Header for Transfermark.com website(for market valuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code Section to fetch Player Market Valuations from TransferMarket Website##\n",
    "page = \"https://www.transfermarkt.us/premier-league/daten/wettbewerb/GB1\"\n",
    "pageTree = requests.get(page, headers=headers)\n",
    "pageSoup_teams = BeautifulSoup(pageTree.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fetch the teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams = []\n",
    "Teams_mod = []\n",
    "for table in pageSoup_teams.find_all('table', class_='items'):\n",
    "    #time.sleep(20)\n",
    "    for link in table.find_all('a'):\n",
    "        temp = \"https://www.transfermarkt.us\" + link.get(\"href\") \n",
    "        Teams.append(temp)\n",
    "  ## Notice that there are redundant links in the list so I am filtering out the duplicate values      \n",
    "    [Teams_mod.append(x) for x in Teams if x not in Teams_mod]\n",
    "\n",
    "Teams_corr = Teams_mod[4::2] #This is to clean-up redundant and un-necessary links in the data     \n",
    "Teams_corr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams_corr[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_page_temp = []\n",
    "team_page_temp = Teams_corr[0:5]\n",
    "print(team_page_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fetch players from each of the teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams_Players_Names = []\n",
    "Teams_Players_Valuations_2016 = []\n",
    "Teams_Players_Valuations_2017 = []\n",
    "Teams_Players_Names_2017 = []\n",
    "Teams_Players_Positions = []\n",
    "Teams_Players = []\n",
    "Teams_Players_mod = []\n",
    "team_page_temp = []\n",
    "Player_2016 = {}\n",
    "Player_2017 = []\n",
    "#team_page_temp = Teams_corr[0:11]\n",
    "player_valuations_dataframe = pd.DataFrame()\n",
    "#for team_pa'https://www.transfermarkt.us/chelsea-fc/startseite/verein/631?saison_id=20ge in Teams_corr: ## For each team in the list -> we go ahead to fetch the players\n",
    "test_page = \"https://www.transfermarkt.us/fc-everton/startseite/verein/29\"\n",
    "#team_page_temp.append(Teams_corr[0:1])\n",
    "#team_page_temp.append(test_page)\n",
    "for team_page in Teams_corr: ## We Look through the list and fetch every team and load their respective pages \n",
    "    \n",
    "    #time.sleep(20)\n",
    "    #print(team_page)\n",
    "    #a_dict = collections.defaultdict(list)\n",
    "    #a_dict[\"a\"].append(\"hello\")\n",
    "    #print(a_dict)\n",
    "    #OUTPUT\n",
    "    #defaultdict(<class 'list'>, {'a': ['hello']})\n",
    "    #a_dict[\"a\"].append(\"kite\")\n",
    "    #print(a_dict)\n",
    "\n",
    "    team_page_2016 = team_page +  \"?saison_id=2016\"\n",
    "    pageTree = requests.get(team_page_2016, headers=headers)\n",
    "    pageSoup_player = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "    for table in pageSoup_player.find_all('table', class_='items'):\n",
    "        #for link in table.find_all('td'):\n",
    "        for player_link in table.find_all('a',class_ = 'spielprofil_tooltip'):\n",
    "                player_name = player_link.get(\"title\")\n",
    "                if player_name not in Teams_Players_Names:\n",
    "                    Teams_Players_Names.append(player_name)\n",
    "                #print(player_name)\n",
    "        for player_value_link in table.find_all('td',class_= 'rechts hauptlink'):\n",
    "                #player_valuation = player_value_link.text\n",
    "                #if player_valuation == '&nbsp':\n",
    "                #    print('&nbsp')\n",
    "                player_valuation = player_value_link.text.split('\\xa0')[0]\n",
    "                if not player_valuation :\n",
    "                    player_valuation = '0'\n",
    "                Teams_Players_Valuations_2016.append(player_valuation)\n",
    "                #player_valuation = player_value_link.text\n",
    "                #player_valuation = player_valuation.split(\"\\\")[0]\n",
    "                #print(player_valuation)                                                \n",
    "                #if not player_valuation:\n",
    "                #    player_valuation = 'N/A'\n",
    "                #Teams_Players_Valuations_2016.append(player_valuation)\n",
    "        \n",
    "                #print(player_valuation)\n",
    "            #if player_name not in Player_2016:\n",
    "    Teams_Players_Valuations_2016 = Teams_Players_Valuations_2016[0:776]\n",
    "    Player_2016 = {'Player': Teams_Players_Names, 'Valuation-2016':Teams_Players_Valuations_2016 }    \n",
    "    \n",
    "    team_page_2017 = team_page +  \"?saison_id=2017\"\n",
    "    pageTree = requests.get(team_page_2017, headers=headers)\n",
    "    pageSoup_player = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "    for table in pageSoup_player.find_all('table', class_='items'):\n",
    "        #for link in table.find_all('td'):\n",
    "        for player_link in table.find_all('a',class_ = 'spielprofil_tooltip'):\n",
    "                player_name = player_link.get(\"title\")\n",
    "                if player_name not in Teams_Players_Names_2017:\n",
    "                    Teams_Players_Names_2017.append(player_name)\n",
    "                #print(player_name)\n",
    "        for player_value_link in table.find_all('td',class_= 'rechts hauptlink'):\n",
    "                #player_valuation = player_value_link.text\n",
    "                #if player_valuation == '&nbsp':\n",
    "                #    print('&nbsp')\n",
    "                player_valuation = player_value_link.text.split('\\xa0')[0]\n",
    "                if not player_valuation :\n",
    "                    player_valuation = '0'\n",
    "                Teams_Players_Valuations_2017.append(player_valuation)\n",
    "                #player_valuation = player_value_link.text\n",
    "                #player_valuation = player_valuation.split(\"\\\")[0]\n",
    "                #print(player_valuation)                                                \n",
    "                #if not player_valuation:\n",
    "                #    player_valuation = 'N/A'\n",
    "                #Teams_Players_Valuations_2016.append(player_valuation)\n",
    "        \n",
    "                #print(player_valuation)\n",
    "            #if player_name not in Player_2016:\n",
    "            \n",
    "    Teams_Players_Valuations_2016 = Teams_Players_Valuations_2016[0:776]\n",
    "    Player_2016 = {'Player': Teams_Players_Names, 'Valuation-2016':Teams_Players_Valuations_2016 }    \n",
    "    Teams_Players_Valuations_2017 = Teams_Players_Valuations_2017[0:732]\n",
    "    Player_2017 = {'Player': Teams_Players_Names_2017, 'Valuation-2017':Teams_Players_Valuations_2017 }    \n",
    "    \n",
    "    \n",
    "    #team_page_2017 = team_page +  \"?saison_id=2017\"\n",
    "    #pageTree = requests.get(team_page_2017, headers=headers)\n",
    "    #pageSoup_player = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "    #for table in pageSoup_player.find_all('table', class_='items'):\n",
    "        #rows = [row for row in table.find_all('a',class_ = 'spielprofil_tooltip')]\n",
    "        #headings = [heading for heading in table.find_all('h1') ]\n",
    "    #try:   \n",
    "        #print(headings[0])\n",
    "    #    player_name   = headings[0].find('span').text\n",
    "        #print(player_name)\n",
    "    #    player_height = rows[2].find_all('span')[0].text\n",
    "    #    player_weight = rows[2].find_all('span')[1].text\n",
    "    #    player_footedness = rows[1].text\n",
    "    #    Player_Attr[player_name] = [player_name] + [player_height] + [player_weight] + [player_footedness]\n",
    "  \n",
    "    #    for link in table.find_all('td'):\n",
    "    #        for link in table.find_all('a',class_ = 'spielprofil_tooltip'):\n",
    "     #           player_name = link.get(\"title\")\n",
    "     #           print(player_name)\n",
    "     #       for link in table.find_all('td',class_= 'rechts hauptlink'):\n",
    "      #          player_valuation = link.text\n",
    "      #          print(player_valuation)\n",
    "            #if player_name not in Player_2017:\n",
    "       #     Player_2017.append([player_name,player_valuation])\n",
    "                \n",
    "        #for link in table.find_all('a', class_ = 'spielprofil_tooltip'):\n",
    "            #print(link)\n",
    "        #    if (link.get(\"title\")) not in Player_2016:\n",
    "         #       Player_2016[link.get(\"title\")] = link.get(\"title\")\n",
    "            #else:\n",
    "                #Player_2016.setdefault(link.get(\"title\"), [])\n",
    "                #Player_2016[link.get(\"title\")].append(link.get(\"title\"))\n",
    "                #Teams_Players_Names.append(link.get(\"title\"))\n",
    "                #Player_Attr[link.get(\"title\")] = link.get(\"title\")\n",
    "\n",
    "        #for link in table.find_all('td', class_ = 'rechts hauptlink'):\n",
    "                #Player_2016.setdefault(link.get(\"title\"), [])\n",
    "        #        print(link)\n",
    "        #        print(link.get(\"title\"))\n",
    "        #        print(link.text)\n",
    "        #        Player_2016[link.get(\"title\")] = link.text\n",
    "                #Teams_Players_Valuations_2016.append(link.text)\n",
    "    \n",
    "    #team_page = team_page +  \"?saison_id=2017\"\n",
    "    #pageTree = requests.get(team_page, headers=headers)\n",
    "    #pageSoup_player = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "    #for table in pageSoup_player.find_all('table', class_='items'):\n",
    "    #    for link in table.find_all('a', class_ = 'spielprofil_tooltip'):\n",
    "    #        if (link.get(\"title\")) not in Player_2017:\n",
    "    #            Player_2017[link.get(\"title\")] = link.get(\"title\")\n",
    "        #for link in table.find_all('a', class_ = 'spielprofil_tooltip'):\n",
    "        #    if (link.get(\"title\")) not in Teams_Players_Names:\n",
    "        #        Teams_Players_Names.append(link.get(\"title\"))\n",
    "                #Player_Attr[link.get(\"title\")] = link.get(\"title\")\n",
    "    #    for link in table.find_all('td', class_ = 'rechts hauptlink'):\n",
    "    #            Player_2017[link.get(\"title\")] = link.text\n",
    "                #Teams_Players_Valuations_2017.append(link.text)\n",
    "                \n",
    "                \n",
    "Players_Attr_df_2016 = pd.DataFrame(Player_2016, columns = ['Player','Valuation-2016'])  #transpose\n",
    "Players_Attr_df_2016.columns = ['Player','Valuation-2016']\n",
    "Players_Attr_df_2016.set_index('Player', inplace= True)\n",
    "Players_Attr_df_2017 = pd.DataFrame(Player_2017, columns = ['Player','Valuation-2017'])  #transpose\n",
    "Players_Attr_df_2017.columns = ['Player','Valuation-2017']\n",
    "Players_Attr_df_2017.set_index('Player', inplace= True)\n",
    "merged_valuation_df = Players_Attr_df_2016.merge(Players_Attr_df_2017, how='inner', left_on='Player', right_on='Player')\n",
    "#Players_Attr_df.columns = ['Player','Valuation_2016','Valuation_2017'] \n",
    "#Players_Attr_df.set_index('Player', inplace= True)\n",
    "#Players_Attr_df['Player'] = Teams_Players_Names\n",
    "#Players_Attr_df['Valuation_2016'] = Teams_Players_Valuations_2016\n",
    "#Players_Attr_df['Valuation_2017'] = Teams_Players_Valuations_2017\n",
    "#Players_Attr_df.set_index('Player', inplace= True)\n",
    "print(len(Teams_Players_Valuations_2017))\n",
    "print(len(Teams_Players_Names_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Attr_df_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_valuation_df_copy = merged_valuation_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Merge with the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df = Players_Info_outer_merged.merge(merged_valuation_df,how='inner', left_on='Player', right_on='Player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df.dropna();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df = pd.read_pickle(r'Players_Dataset_df_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Fetch information from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pageviewapi\n",
    "total_views = 0\n",
    "counter = 0\n",
    "for row in Players_Dataset_df.iterrows():\n",
    "    #print(row[1].name);\n",
    "    #print(index)\n",
    "    #print(row)\n",
    "    #print(row[0])\n",
    "    #total_views = 0\n",
    "    player_name = row[0]\n",
    "    #print(row[0])\n",
    "    try:\n",
    "        page_views = pageviewapi.per_article('en.wikipedia', player_name , '20160801', '20170801',\n",
    "                                access='all-access', agent='all-agents', granularity='monthly')\n",
    "    \n",
    "        for i in range(len(page_views['items'])):\n",
    "            total_views += page_views['items'][i]['views']\n",
    "    \n",
    "        \n",
    "        Players_Dataset_df.loc[row[0], 'Wiki_Views'] = total_views\n",
    "        total_views = 0\n",
    "\n",
    "    except:\n",
    "        total_views = 0\n",
    "        Players_Dataset_df.loc[row[0], 'Wiki_Views'] = total_views\n",
    "        continue \n",
    "    \n",
    "    #counter +=1\n",
    "    #row.loc[]\n",
    "    #Players_Dataset_df.loc[row.Index, 'Wiki_Views'] = total_views    \n",
    "#print(page_views['items'][0]['views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_wiki = Players_Dataset_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pick Selective DataSet for Model-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pickle this Dataset to be used for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df.to_pickle(\"Players_Dataset_df_1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_wiki.to_pickle(\"Players_Dataset_df_Wiki_1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy = pd.read_pickle(r'Players_Dataset_df_Wiki_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataCleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = Players_Dataset_df_copy.loc['Islam Slimani',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy.Nation = Players_Dataset_df_copy.Nation.str[-1:-4:-1] # Clean the nation column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"\\u25AA\")\n",
    "#import string\n",
    "#str.replace(Players_Dataset_df_copy.Footedness[0],(\"\\xa0\\u25A0\\xa0\"),\",\")\n",
    "Players_Dataset_df_copy[['Position','Footedness']] = Players_Dataset_df_copy['Footedness'].str.split('\\xa0\\u25AA\\xa0', 1,expand=True)\n",
    "Players_Dataset_df_copy[['Footed','Footedness']] = Players_Dataset_df_copy['Footedness'].str.split(':', 1,expand=True)\n",
    "\n",
    "#print(test1)\n",
    "#Players_Dataset_df_copy.Footedness[0]\n",
    "#['Fremont', '\\xc2\\xb7', 'Full', 'Time']\n",
    "#import string\n",
    "#string.replace(a,'\\xc2\\xb7',\"\")\n",
    "#'Fremont  Full Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy[['Random_no','Footedness']] = Players_Dataset_df_copy['Footedness'].str.split('%', 1,expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy['Footedness'] = Players_Dataset_df_copy['Footedness'].str[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy['Pos'] = Players_Dataset_df_copy['Pos'].str.split(',', 1,expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Players_Dataset_df_copy['Position'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Players_Dataset_df_copy['Footed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Players_Dataset_df_copy['Random_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_2 = Players_Dataset_df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_2['Valuation-2016'] = Players_Dataset_df_copy_2['Valuation-2016'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_2['Valuation-2017'] = Players_Dataset_df_copy_2['Valuation-2017'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_2.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_2['Height'] = Players_Dataset_df_copy_2['Height'].str[:3:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_2['Weight'] = Players_Dataset_df_copy_2['Weight'].str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3 = Players_Dataset_df_copy_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3['Valuation-2016_Unit']= Players_Dataset_df_copy_3['Valuation-2016'].str[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3['Valuation-2016']= Players_Dataset_df_copy_3['Valuation-2016'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3['Valuation-2016']= Players_Dataset_df_copy_3['Valuation-2016'].str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3['Valuation-2017_Unit']= Players_Dataset_df_copy_3['Valuation-2017'].str[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3['Valuation-2017']= Players_Dataset_df_copy_3['Valuation-2017'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc['Islam Slimani',:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3['Valuation-2017']= Players_Dataset_df_copy_3['Valuation-2017'].str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc['Islam Slimani',:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3[\"Valuation-2016\"] = pd.to_numeric(Players_Dataset_df_copy_3[\"Valuation-2016\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3[\"Valuation-2017\"] = pd.to_numeric(Players_Dataset_df_copy_3[\"Valuation-2017\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc['Islam Slimani',:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3['Valuation-2017_Unit'] = Players_Dataset_df_copy_3['Valuation-2017_Unit'].str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3['Valuation-2016_Unit'] = Players_Dataset_df_copy_3['Valuation-2016_Unit'].str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = Players_Dataset_df_copy_3.loc['Islam Slimani',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc[Players_Dataset_df_copy_3['Valuation-2016_Unit'] == 'm'  ,'Valuation-2016']= Players_Dataset_df_copy_3['Valuation-2016'] * 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc['Islam Slimani',:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc[Players_Dataset_df_copy_3['Valuation-2016_Unit'] == '.'  ,'Valuation-2016']= Players_Dataset_df_copy_3['Valuation-2016'] *1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc['Islam Slimani',:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc[Players_Dataset_df_copy_3['Valuation-2017_Unit'] == 'm'  ,'Valuation-2017']= Players_Dataset_df_copy_3['Valuation-2017'] * 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc[Players_Dataset_df_copy_3['Valuation-2017_Unit'] == '.'  ,'Valuation-2017']= Players_Dataset_df_copy_3['Valuation-2017'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.loc['Islam Slimani',:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_3.to_pickle(\"Cleaned_DataSet_1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_4 = Players_Dataset_df_copy_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Players_Dataset_df_copy_4['Valuation-2016_Unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Players_Dataset_df_copy_4['Valuation-2017_Unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Players_Dataset_df_copy_4['PlLink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_4.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_4['Height'] = Players_Dataset_df_copy_4['Height'].str.replace(\"\\n \",\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_4.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_4.dropna();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_copy_4.isnull().any();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_NaN = Players_Dataset_df_copy_4.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = Players_Dataset_df_copy_4[row_has_NaN]\n",
    "\n",
    "#print(rows_with_NaN);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean =Players_Dataset_df_copy_4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.isnull().any();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.to_pickle(\"Complete_DataSet_1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.info(); #Checking the dataypes of my clean dataset;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.replace(',','', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_convert=['Age','MP','Starts','Min','Gls','Ast','PK','90s','PKatt','CrdY','CrdR','PGls','PAst','PG+A','PG-PK','PG+A-PK','Height','Weight']\n",
    "for col in cols_to_convert:\n",
    "    Players_Dataset_df_clean[col] = pd.to_numeric(Players_Dataset_df_clean[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean['Valuation-2016'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.to_pickle(\"Complete_DataSet_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.rename(columns={'Valuation-2016': 'Value' ,'Valuation-2017': 'Target' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 5 Valuable Player\n",
    "Players_Dataset_df_clean.nlargest(5,columns=\"Value\")[[\"Player\",\"Age\",\"Team\",\"Value\"]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 5 Rating Player\n",
    "Players_Dataset_df_clean.nlargest(5,columns=\"Wiki_Views\")[[\"Player\",\"Age\",\"Team\",\"Wiki_Views\"]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Value (Top 5) based on Position\n",
    "\n",
    "pd.DataFrame(Players_Dataset_df_clean.groupby(\"Pos\").Value.mean().sort_values(ascending=False)).head(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 5 Clup (Mean Value)\n",
    "\n",
    "pd.DataFrame(Players_Dataset_df_clean.groupby(\"Team\").Value.mean().sort_values(ascending=False).head(5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 5 Clup (Total Value)\n",
    "\n",
    "pd.DataFrame(Players_Dataset_df_clean.groupby(\"Team\").Value.sum().sort_values(ascending=False).head(5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age , Height and Weight Stats\n",
    "Players_Dataset_df_clean[[\"Age\",\"Height\",\"Weight\"]].describe();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot the Box graph for the \"2016-Market Valuation\"\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.boxenplot(y='Value', data=Players_Dataset_df_clean, width=0.5)\n",
    "#sns.boxenplot(y='Value', data=Players_Dataset_df_clean, width=0.5)\n",
    "ax.set_title('2016 Market Valuation')\n",
    "#ax.set_xlabel('xlabel')\n",
    "ax.set_ylabel('Market Valuation')\n",
    "#ax.set_title('axes title')\n",
    "#ax.set_xlabel('xlabel')\n",
    "#ax.set_ylabel('ylabel')\n",
    "plt.savefig('boxplot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "#ax = fig.add_subplot(111)\n",
    "#ax.boxplot(data)\n",
    "\n",
    "ax.set_title('2016 Market Valuation')\n",
    "#ax.set_xlabel('xlabel')\n",
    "ax.set_ylabel('Market Valuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Frequency Distribution of Player \n",
    "x = Players_Dataset_df_clean.Value\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(x).set_title('Frequency Distribution Plot of Player Actual Values')\n",
    "plt.savefig('boxplot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot of Player Values - 2016 Market Valuation\n",
    "fig = plt.figure(1, figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax.set_title('2016 Market Valuation')\n",
    "ax.set_ylabel('Players Count')\n",
    "ax.set_xlabel('Market Valuation')\n",
    "plt.hist( x= 'Value', bins=25,data=Players_Dataset_df_clean)\n",
    "#plt.title('Value distribution of all players')\n",
    "plt.savefig('Hist.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Wiki-views with Player Valuation - 2016 Player Valuations\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.regplot(x=\"Value\",y=\"Wiki_Views\",data=Players_Dataset_df_clean)\n",
    "plt.savefig('Wiki_Views.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Position with respect to 2016 - Market Valuation\n",
    "plt.figure(figsize=(10,10),dpi=200)\n",
    "graph = sns.catplot(y=\"Pos\", x=\"Value\", kind=\"bar\",  data=Players_Dataset_df_clean)\n",
    "plt.savefig('Pos.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the correlations of the features\n",
    "corr_mat = Players_Dataset_df_clean.corr()\n",
    "corr_mat;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation With Value (most correlated with positive)\n",
    "pd.DataFrame(corr_mat[\"Value\"]).sort_values(\"Value\", ascending=False).head(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation With Value (modes correlated with negative)\n",
    "pd.DataFrame(corr_mat[\"Value\"]).sort_values(\"Value\", ascending=True).head(7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice data into Features and Target values.\n",
    "\n",
    "Players_Dataset_df_clean_model = Players_Dataset_df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the infinity with NA and drop them later \n",
    "Players_Dataset_df_clean_model_2 = Players_Dataset_df_clean_model.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean_model_2.dropna();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill for any missing values and we make sure that we have no nulls or NAs\n",
    "Players_Dataset_df_clean_model_2 = Players_Dataset_df_clean_model_2.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean_model_2.isnull().sum();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the model to be used below for the OLS.\n",
    "Xb= Players_Dataset_df_clean_model_2.drop(columns=[\"Player\",\"Team\",\"Nation\",\"Pos\",\"Footedness\",\"Target\"])\n",
    "yb= Players_Dataset_df_clean_model_2.loc[:,\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with target as player market value(2017)\n",
    "player_modelb = sm.OLS(yb, Xb, data=Players_Dataset_df_clean_model_2)\n",
    "\n",
    "resultsb = player_modelb.fit()\n",
    "\n",
    "print(resultsb.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1= Players_Dataset_df_clean_model_2.loc[:,['MP','Age','Min','Gls','Ast','CrdY','CrdR','Height','Weight','Value','Wiki_Views']]\n",
    "y1= Players_Dataset_df_clean_model_2.loc[:,\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what coefficients our regression model has chosen\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X1,y1)\n",
    "coeff_df = pd.DataFrame(regressor.coef_, X1.columns, columns=['Coefficient'])  \n",
    "coeff_df.sort_values(\"Coefficient\",ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Prediction on all data and calculate difference between tha actual value and predicted value\n",
    "y_pred = regressor.predict(X1)\n",
    "df = pd.DataFrame({'Name':Players_Dataset_df_clean_model_2.Player,'Actual': y1, 'Predicted': y_pred})\n",
    "df[\"Difference\"] = df[\"Actual\"]-df[\"Predicted\"]\n",
    "df_under = round(df.sort_values('Difference').set_index('Name').head(10),2)\n",
    "df_over = round(df.sort_values('Difference').set_index('Name').tail(10),2)\n",
    "df_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the comparision of Actual and Predicted Values for Under Predicted\n",
    "df_over[[\"Actual\",\"Predicted\"]].plot(kind='bar',figsize=(10,5))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.title(\"Actual vs Predicted Values\")\n",
    "plt.xlabel(\"Player Name\")\n",
    "plt.ylabel('Value')\n",
    "plt.savefig('AVP.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the comparision of Actual and Predicted Values for Over Predicted\n",
    "\n",
    "df_under[[\"Actual\",\"Predicted\"]].plot(kind='bar',figsize=(10,5))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.title(\"Actual vs Predicted Values for Over Predicted\")\n",
    "plt.xlabel(\"Player Name\")\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Residuals\n",
    "plt.figure(figsize=(10,6),dpi=100),\n",
    "plt.style.use('default')\n",
    "plt.scatter(resultsb.predict(), resultsb.resid);\n",
    "plt.title(\"Predicted Values and Residuals\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean_model_2_features = Players_Dataset_df_clean_model_2.drop(columns=[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players_Dataset_df_clean_model_2_features.columns # Few features are redundant but for now lets keep them all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of correlated values- for all the features (a lot of feature are redundant)\n",
    "plt.figure(1, figsize=(18, 7))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.heatmap(Players_Dataset_df_clean_model_2_features.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1)\n",
    "plt.yticks(rotation=0); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Pair Plots\n",
    "plt.figure(1, figsize=(18, 7))\n",
    "sns.set(style=\"whitegrid\")\n",
    "g=sns.pairplot(Players_Dataset_df_clean_model_2_features, height=1.2, aspect=1.5)\n",
    "plt.yticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Model-1 with the features that we need \n",
    "X1= Players_Dataset_df_clean_model_2.loc[:,['MP','Age','Min','Gls','Ast','CrdY','CrdR','Height','Weight','Value','Wiki_Views']]\n",
    "y1= Players_Dataset_df_clean_model_2.loc[:,\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the pair plot for the selected features.\n",
    "plt.figure(1, figsize=(18, 7))\n",
    "sns.set(style=\"whitegrid\")\n",
    "g=sns.pairplot(X1, height=1.2, aspect=1.5)\n",
    "plt.yticks(rotation=90); \n",
    "plt.savefig('PP.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of correlated values- for selected features\n",
    "plt.figure(1, figsize=(18, 7))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.heatmap(X1.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1)\n",
    "plt.yticks(rotation=0); \n",
    "plt.savefig('Corr.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model1 - Linear Regression\n",
    "#Split data into train, test and validation (%60 - %20 - 2-%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1,y1,test_size=0.2, random_state=10)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X1,y1, test_size=.25, random_state=10)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "pred = lr.predict(X_val)\n",
    "mse = np.mean((pred-y_val)**2)\n",
    "\n",
    "print(lr.score(X_test,y_test)) # Get the R^2\n",
    "print(mse) # Get the Mean Square Error \n",
    "print(lr.coef_) # Get the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.DataFrame(X_train.columns)\n",
    "\n",
    "coeff['CoefficientEstimate'] = lr.coef_\n",
    "\n",
    "coeff.sort_values(\"CoefficientEstimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 4 models we're choosing from:\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values) # Scale Training data \n",
    "X_val_scaled = scaler.transform(X_val.values) # Scale validation data\n",
    "X_test_scaled = scaler.transform(X_test.values)# Scale Test data \n",
    "\n",
    "lm_reg = Ridge(alpha=0.05, normalize=True) # Ridge optimization \n",
    "\n",
    "lm_lasso = Lasso(alpha=0.05, normalize=True)# LASSO optimization\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "poly = PolynomialFeatures(degree=2) #Polynomial model\n",
    "\n",
    "X1_poly = poly.fit_transform(X1.values)\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_val_poly = poly.transform(X_val.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear Regression for all data R^2: {lm.score(X1, y1):.3f}')\n",
    "print(f'Linear Regression for validation data R^2: {lm.score(X_val, y_val):.3f}')\n",
    "print(f'Linear Regression for test data R^2: {lm.score(X_test, y_test):.3f}')\n",
    "print(\"\")\n",
    "\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge Regression for validation data R^2: {lm_reg.score(X_val_scaled, y_val):.3f}')\n",
    "print(f'Ridge Regression for test data R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "lm_lasso.fit(X_train_scaled,y_train)\n",
    "print(f'Lasso Regression for validation data R^2: {lm_lasso.score(X_val, y_val):.6f}')\n",
    "print(f'Lasso Regression for test data R^2: {lm_lasso.score(X_test, y_test):.6f}')\n",
    "print(\"\")\n",
    "\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(f'Degree 2 polynomial regression for validayion data R^2: {lm_poly.score(X_val_poly, y_val):.3f}')\n",
    "print(f'Degree 2 polynomial regression for test data R^2: {lm_poly.score(X_test_poly, y_test):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= sm.OLS(y1, X1, data=Players_Dataset_df_clean_model_2)\n",
    "\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Variables for Position\n",
    "\n",
    "X3 = pd.concat([Players_Dataset_df_clean_model_2_features.drop('Pos', axis=1), pd.get_dummies(Players_Dataset_df_clean_model_2['Pos'])],axis=1)\n",
    "\n",
    "X3 = X3.drop(columns=[\"Team\",\"Player\",\"Footedness\",\"Wiki_Views\",\"Nation\"])\n",
    "\n",
    "y3 = yb= Players_Dataset_df_clean_model_2.loc[:,\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with target as player market value \n",
    "player_model3 = sm.OLS(y3, X3, data=Players_Dataset_df_clean_model_2)\n",
    "\n",
    "results3 = player_model3.fit()\n",
    "\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Cross Validation - 10 splits \n",
    "\n",
    "lm = LinearRegression()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state = 100)\n",
    "#cross_val_score(lm, X1, y1, cv=kf, scoring='r2')\n",
    "\n",
    "print(round(np.mean(cross_val_score(lm, X1, y1, cv=kf, scoring='r2')),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Assumptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumption 1: regression is linear in parameters and correctly specified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Fit\n",
    "plt.figure(figsize=(10,6),dpi=150),\n",
    "lr = LinearRegression()\n",
    "fit = lr.fit(X1,y1);\n",
    "pred = lr.predict(X1)\n",
    "plt.scatter(pred,y1)\n",
    "plt.title(\"Regression Fit\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Q-Q Plot\n",
    "df['predict']=(regressor.predict(X1))\n",
    "df['resid']= (y1-df.predict)\n",
    "plt.figure(figsize=(10,6),dpi=150),\n",
    "stats.probplot(df['resid'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumption 2: residuals should be normally distributed with zero mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot your predicted values on the x-axis, and your residuals on the y-axis\n",
    "\n",
    "player_model = sm.OLS(y1, X1, data=Players_Dataset_df_clean_model_2)\n",
    "\n",
    "resultsl = player_model.fit()\n",
    "\n",
    "plt.figure(figsize=(10,6),dpi=150),\n",
    "plt.style.use('default')\n",
    "plt.scatter(resultsl.predict(), resultsl.resid);\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumption 3: Homoscedasticity test for residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram\n",
    "plt.figure(figsize=(10,6),dpi=150),\n",
    "\n",
    "y1.hist();\n",
    "2\n",
    "# note the positive skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick reg plot\n",
    "plt.figure(figsize=(10,6),dpi=150),\n",
    "\n",
    "\n",
    "plt.scatter(X1.Value,y1)\n",
    "plt.scatter(X1.Value,df.predict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6),dpi=150),\n",
    "np.log(y1).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumption 4: Detecting correlation between residuals and observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to show optimal lambda values\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "prob = stats.boxcox_normplot(Players_Dataset_df_clean_model_2.Value, -3, 5, plot=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
